<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0" uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Top 10: Our most read developer articles of 2021</title><link rel="alternate" href="https://developers.redhat.com/articles/2021/12/27/top-10-our-most-read-developer-articles-2021" /><author><name>Red Hat Developer Editorial Team</name></author><id>70db31e2-087e-4351-b257-36597cc455fc</id><updated>2021-12-27T07:00:00Z</updated><published>2021-12-27T07:00:00Z</published><summary type="html">&lt;p&gt;We're taking a quick break from the winter recharge to share our 10 most read articles of 2021. Some of the best developers in the world work for Red Hat, and we're fortunate that many of them contribute to Red Hat Developer. We think this year's top 10 articles showcase the breadth of our contributors' interests and expertise, as well as that of our readers. Without further ado, here are Red Hat Developer's most popular articles of 2021.&lt;/p&gt; &lt;h2&gt;1. How to activate your no-cost Red Hat Enterprise Linux subscription&lt;/h2&gt; &lt;p&gt;Following the January 2020 announcement of Red Hat's new &lt;a href="https://developers.redhat.com/products/rhel/download"&gt;no-cost Red Hat Enterprise Linux (RHEL) subscription&lt;/a&gt;, this article walks you through everything you need to set up a subscription in three easy steps. No wonder &lt;a href="https://developers.redhat.com/author/miroslav-suchy"&gt;Miroslav Suchý&lt;/a&gt;'s &lt;a href="https://developers.redhat.com/blog/2021/02/10/how-to-activate-your-no-cost-red-hat-enterprise-linux-subscription"&gt;How to activate your no-cost Red Hat Enterprise Linux subscription&lt;/a&gt; was our most-read article in 2021!&lt;/p&gt; &lt;h2&gt;2. Distributed transaction patterns for microservices compared&lt;/h2&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/authors/bilgin-ibryam"&gt;Bilgin Ibryam&lt;/a&gt; is co-author of the &lt;a href="https://developers.redhat.com/books/kubernetes-patterns"&gt;Kubernetes Patterns&lt;/a&gt; e-book and a frequent contributor, with over a dozen articles published on Red Hat Developer to date. In &lt;a href="https://developers.redhat.com/articles/2021/09/21/distributed-transaction-patterns-microservices-compared"&gt;Distributed transaction patterns for microservices compared&lt;/a&gt;, he discusses the benefits and drawbacks of five distributed transaction patterns and addresses one of the pain points of modernizing monolithic applications into &lt;a href="https://developers.redhat.com/topics/microservices"&gt;microservices&lt;/a&gt;. We expect readers will seek out this article for years to come.&lt;/p&gt; &lt;h2&gt;3. Application modernization patterns with Apache Kafka, Debezium, and Kubernetes&lt;/h2&gt; &lt;p&gt;Another article in Bilgin's series tackling the challenges of modernizing legacy applications, this one offers both a well-tested pattern (Strangler, used in tandem with Outbox, Sidecar, and Saga) and standardized tools for implementing it. &lt;a href="https://developers.redhat.com/articles/2021/06/14/application-modernization-patterns-apache-kafka-debezium-and-kubernetes"&gt;Application modernization patterns with Apache Kafka, Debezium, and Kubernetes&lt;/a&gt; is a must-read for developers interested in using &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; and &lt;a href="https://developers.redhat.com/topics/kafka-kubernetes"&gt;Apache Kafka&lt;/a&gt; to create robust systems that evolve over time.&lt;/p&gt; &lt;h2&gt;4. Making environment variables accessible in front-end containers&lt;/h2&gt; &lt;p&gt;We published many articles in 2021 about developing and deploying applications in &lt;a href="https://developers.redhat.com/topics/containers"&gt;containers&lt;/a&gt;, but this one stood out for its focus on building containers for single-page &lt;a href="https://developers.redhat.com/topics/javascript"&gt;JavaScript&lt;/a&gt; applications. As author &lt;a href="https://developers.redhat.com/authors/joel-lord"&gt;Joel Lord&lt;/a&gt; explains, the application's configuration settings will be different depending on where the container runs, and the challenge is how to make those settings accessible in any environment. &lt;a href="https://developers.redhat.com/blog/2021/03/04/making-environment-variables-accessible-in-front-end-containers"&gt;Making environment variables accessible in front-end containers&lt;/a&gt; leaves you with a solution that you can reuse for any of your future JavaScript projects.&lt;/p&gt; &lt;h2&gt;5. C# 9 top-level programs and target-typed expressions&lt;/h2&gt; &lt;p&gt;Red Hatter and .NET Core developer &lt;a href="https://developers.redhat.com/author/tom-deseyn"&gt;Tom Deseyn&lt;/a&gt;'s C# 9 language features series was our most popular series this year. This article, &lt;a href="https://developers.redhat.com/blog/2021/03/30/c-9-top-level-programs-and-target-typed-expressions"&gt;C# 9 top-level programs and target-typed expressions&lt;/a&gt;, started it all.&lt;/p&gt; &lt;h2&gt;6. C# 9 pattern matching&lt;/h2&gt; &lt;p&gt;The second article in the C# 9 series, &lt;a href="https://developers.redhat.com/blog/2021/04/06/c-9-pattern-matching"&gt;C# 9 pattern matching&lt;/a&gt; introduces changes to pattern matching in C# 9, including updates and support for combining, inverting, and nesting patterns. A breezy read with many code samples for developers adopting C# 9.&lt;/p&gt; &lt;h2&gt;7. Why should I choose Quarkus over Spring for my microservices?&lt;/h2&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/topics/quarkus"&gt;Quarkus&lt;/a&gt; is one of our most popular topics on Red Hat Developer, and &lt;a href="https://developers.redhat.com/articles/2021/08/31/why-should-i-choose-quarkus-over-spring-my-microservices"&gt;this article&lt;/a&gt; by Quarkus and Spring Boot developer &lt;a href="https://developers.redhat.com/author/eric-deandrea"&gt;Eric Deandrea&lt;/a&gt; helps to explain why. Find out why many Spring developers are switching to Quarkus and how to get started using the Kubernetes-native Java platform for your microservices.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you're ready to make the leap from Spring to Quarkus, see Eric's e-book, &lt;a href="https://developers.redhat.com/e-books/quarkus-spring-developers"&gt;Quarkus for Spring Developers&lt;/a&gt;, published by Red Hat Developer in August 2021.&lt;/p&gt; &lt;h2&gt;8. Shenandoah in OpenJDK 17: Sub-millisecond GC pauses&lt;/h2&gt; &lt;p&gt;The Shenandoah OpenJDK garbage collection project was created to reduce garbage collection pause times, and &lt;a href="https://developers.redhat.com/articles/2021/09/16/shenandoah-openjdk-17-sub-millisecond-gc-pauses"&gt;this article&lt;/a&gt; concludes a series explaining how the Shenandoah team did it. Shenandoah GC Project Lead &lt;a href="https://developers.redhat.com/author/roman-kennke"&gt;Roman Kennke&lt;/a&gt; opens with a retrospective of pause time improvements from JDK 12 through 16, then describes how introducing concurrent thread stack processing solved the remaining garbage collection pause-time challenge in JDK 17.&lt;/p&gt; &lt;h2&gt;9. Deploy Helm charts with Jenkins CI/CD in Red Hat OpenShift 4&lt;/h2&gt; &lt;p&gt;This &lt;a href="https://developers.redhat.com/articles/2021/05/24/deploy-helm-charts-jenkins-cicd-red-hat-openshift-4"&gt;quick read&lt;/a&gt; by &lt;a href="https://developers.redhat.com/author/shailendra-kumar-singh"&gt;Shailendra Kumar Singh&lt;/a&gt; gets you started with Helm and Jenkins CI/CD in a step-by-step tutorial. Start with an overview of the Helm package manager for Kubernetes, then create and deploy your first Helm chart and use it to deploy an application using Jenkins CI/CD and &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift.&lt;/a&gt; A simple, practical introduction written for beginners.&lt;/p&gt; &lt;h2&gt;10. How to work around Docker's new download rate limit on OpenShift&lt;/h2&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/2021/02/18/how-to-work-around-dockers-new-download-rate-limit-on-red-hat-openshift"&gt;This article&lt;/a&gt;, a response to Docker's new download rate limits for anonymous users, introduced in November 2020, explains how to get around the unwanted &lt;code&gt;toomanyrequests&lt;/code&gt; error without upgrading to a paid Docker account. Note that this hack, presented by &lt;a href="https://developers.redhat.com/authors/joel-lord"&gt;Joel Lord&lt;/a&gt;, is specifically for developers experimenting with a free OpenShift cluster in the &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;We hope you've enjoyed this recap of Red Hat Developer's 10 most read articles and tutorials published in 2021. During the past year, we've had the pleasure of publishing hundreds of technical articles and other resources (such as &lt;a href="https://developers.redhat.com/cheat-sheets"&gt;cheat sheets&lt;/a&gt;, &lt;a href="https://developers.redhat.com/learn"&gt;interactive courses&lt;/a&gt;, and &lt;a href="https://developers.redhat.com/developer-sandbox/get-started"&gt;Developer Sandbox activities&lt;/a&gt;) written by developers working at Red Hat. See the following for more of our most sought articles and other resources in 2021:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2021/12/01/kubernetes-and-openshift-best-2021"&gt;The best of Kubernetes and OpenShift&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2021/12/08/red-hat-enterprise-linux-best-2021"&gt;The best of Red Hat Enterprise Linux&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2021/12/15/ansible-and-automation-best-2021"&gt;The best of Ansible and automation&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2021/12/22/java-quarkus-kafka-and-more-best-2021"&gt;The best of Java, Quarkus, Kafka, and more&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Happy New Year from all of us on the Red Hat Developer editorial team!&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/12/27/top-10-our-most-read-developer-articles-2021" title="Top 10: Our most read developer articles of 2021"&gt;Top 10: Our most read developer articles of 2021&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Red Hat Developer Editorial Team</dc:creator><dc:date>2021-12-27T07:00:00Z</dc:date></entry><entry><title type="html">Installing Fedora 35 on Macbook Pro 13 inch (late 2011)</title><link rel="alternate" href="http://www.schabell.org/2021/12/installing-fedora-35-on-macbook-pro-13-inch-late-2011.html" /><author><name>Eric D. Schabell</name></author><id>http://www.schabell.org/2021/12/installing-fedora-35-on-macbook-pro-13-inch-late-2011.html</id><updated>2021-12-27T06:00:00Z</updated><content type="html">This weekend I decided to update my old Macbook Pro 13 inch from late 2011, with 125GB SSD and 8GB RAM. It's a machine I've taken on trips around the world and back in the day ran many a session, workshop, or demo on sharing all that AppDev goodness you know from JBoss technologies. Last time we checked, this was , so how about an update to Fedora 35? Below the steps and adjustments needed to  working on this laptops in under an hour. GET FEDORA 35 The first step is to find the right way to install Fedora on this laptop. It does have a CD slot so I guess one could opt for burning an ISO to boot from, but I chose to go straight to a bootable USB option. I got on my other Macbook and visited the  where you find a link to Fedora Media Writer. Just click on the icon (in my case, the apple) for your machine type and you get an installation package.  Install this and start it to see the GUI that guides you through the process. Select the Fedora Workstation 35 option: Next you can select the top right button to Create Live USB option: Then you'll see the image start to download and the drop down menu for selecting where to install the image. If you now plug in an USB stick with the right size available, you can select and install the image directly onto the USB device: Once finished just close this GUI and remove the USB stick.  INSTALLING ON MACBOOK PRO 13 INCH (LATE 2014) Insert the USB stick you created above, there is a port on the left side for this, (re-)start your Macbook Pro and be sure to hold down the Option (or alt) key, just to the left of the CMD key. This opens a menu of options to start this machine from and we'll need to use the EFI option as that's our USB image. Now it's booting from the device and you just can follow the . It really helps if you have a network cable connection you can plug your Macbook Pro into as the wifi device (broadcom) does not work out of the box.  You should get the chance to install to hard drive and put it on your machine permanently. Once you've completed the installer, reboot your machine and you should see Fedora 33 as the option to boot from and end up in your new machine. Now the only thing missing is a wifi driver so there are a few things to be done that require that network cable to be connected as we install the development packages for the kernel we are running and then build the broadcom-wl driver for that kernel. Let's verify the actual card we need for wifi in a terminal: $ lspci -vnn -d 14e4: The output will be several items, one of which should be listing something like: Network controller [0280]: Broadcom Inc. and subsidiaries.... Subsystem: Apple Inc. AirPort Extreme... We now need to install a repository to pull the broadcom stuff as follows: $ su -c 'dnf install -y http://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-$(rpm -E %fedora).noarch.rpm' And then the non-free repository: $ su -c 'dnf install -y http://download1.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release-$(rpm -E %fedora).noarch.rpm' The next part is interesting as you look at the running kernel you'll see v5.15.11-200.fc35 but we are going to be using the development kernel packages to build our broadcom wireless driver so you need to install the v5.14.10-300.fc35 (available at the time of this writing). You can check these using 'uname -r' and list the installed kernel packages using 'sudo dnf list kernel': $ sudo dnf list kernel kernel.x86_64                     5.14.10-300.fc35 kernel.x86_64                     5.15.11-200.fc35 Install the development packages with the following: $ sudo dnf install -y akmods kernel-devel-5.14.10-300.fc35 You'll see a lot of packages scroll by and then the development kernel package install: Now install the Broadcom Wireless package: $ sudo dnf install -y broadcom-wl Now build the kernel module: $ sudo akmods Checking mods exist for 5.15.11-200.fc35.x86_64     [OK] Now reboot your machine and you should be able to view the wireless driver (wl) with the following: $ lsmod | grep wl Now setup your wireless connection in Fedora: Pretty straight forward if you were following along the last time, so hope you enjoyed this end of the year update to the latest Fedora on your old Macbook Pro 13 inch from late 2011! &gt; Starting to look at upgrading my macbook from 2011 by installing 35 on it. &gt; Crossing fingers that the wifi card works without manual intervention. Will be &gt; reporting back soon with the results. Here's the overview of the steps from &gt; last time: &gt; &gt; — Eric D. Schabell (@ericschabell)</content><dc:creator>Eric D. Schabell</dc:creator></entry><entry><title type="html">Quarkus 2.6.1.Final released - Maintenance release</title><link rel="alternate" href="https://quarkus.io/blog/quarkus-2-6-1-final-released/" /><author><name>Guillaume Smet</name></author><id>https://quarkus.io/blog/quarkus-2-6-1-final-released/</id><updated>2021-12-24T00:00:00Z</updated><content type="html">2021 has been a tremendous year for Quarkus and today we officially close our 2021 release season with the last maintenance release of the year: 2.6.1.Final is available on Maven Central and ready for consumption! It is a safe upgrade for anyone already using 2.6 and contains dozens of small...</content><dc:creator>Guillaume Smet</dc:creator></entry><entry><title>More machine learning with OpenShift Data Science</title><link rel="alternate" href="https://developers.redhat.com/articles/2021/12/23/more-machine-learning-openshift-data-science" /><author><name>Audrey Reznik</name></author><id>749ff7cc-63c2-4b3c-b5bc-d8f080295789</id><updated>2021-12-23T07:00:00Z</updated><published>2021-12-23T07:00:00Z</published><summary type="html">&lt;p&gt;We hope you enjoyed the first two &lt;a href="https://developers.redhat.com/products/red-hat-openshift-data-science"&gt;Red Hat OpenShift Data Science&lt;/a&gt; learning paths: &lt;a href="https://developers.redhat.com/products/red-hat-openshift-data-science/getting-started/launch-red-hat-openshift-data-science"&gt;Launch Red Hat OpenShift Data Science&lt;/a&gt; and &lt;a href="https://developers.redhat.com/products/red-hat-openshift-data-science/getting-started/red-hat-openshift-data-science-resources"&gt;OpenShift Data Science documentation and resources&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;This week, we've released two new learning paths, which address the common &lt;a href="https://developers.redhat.com/topics/data-science"&gt;data science&lt;/a&gt; challenges of &lt;a href="https://developers.redhat.com/products/red-hat-openshift-data-science/getting-started/access-download-analyze-s3-data"&gt;accessing Amazon S3 data&lt;/a&gt; and &lt;a href="https://developers.redhat.com/products/red-hat-openshift-data-science/getting-started/create-a-tensorflow-model"&gt;creating a TensorFlow model&lt;/a&gt;. Developers and data scientists can use these hands-on courses to learn how to access data and create machine learning models. You'll also learn how much easier common data science procedures are with OpenShift Data Science.&lt;/p&gt; &lt;p&gt;This article introduces the learning paths and provides an overview of OpenShift Data Science, including where to find more information.&lt;/p&gt; &lt;h2&gt;Accessing Amazon S3 data with OpenShift Data Science&lt;/h2&gt; &lt;p&gt;In this learning path you will learn how to:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Set up your JupyterHub image to use Amazon S3.&lt;/li&gt; &lt;li&gt;Access and download Amazon S3 data from Amazon Web Services (AWS).&lt;/li&gt; &lt;li&gt;Analyze your Amazon S3 data using &lt;a href="https://developers.redhat.com/topics/python"&gt;Python&lt;/a&gt; data frames.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;&lt;a href="https://developers.redhat.com/products/red-hat-openshift-data-science/getting-started/access-download-analyze-s3-data"&gt;Start the learning path&lt;/a&gt; now.&lt;/p&gt; &lt;h2&gt;Creating TensorFlow models in OpenShift Data Science&lt;/h2&gt; &lt;p&gt;In this learning path you will learn how to:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Set up your JupyterHub image to use TensorFlow.&lt;/li&gt; &lt;li&gt;Explore a large public data set (MNIST).&lt;/li&gt; &lt;li&gt;Build, train, and test a TensorFlow model.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;&lt;a href="https://developers.redhat.com/products/red-hat-openshift-data-science/getting-started/create-a-tensorflow-model"&gt;Start the learning path&lt;/a&gt; now.&lt;/p&gt; &lt;p&gt;Remember that you can also try OpenShift Data Science in the &lt;a href="https://developers.redhat.com/developer-sandbox/activities"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; Visit the &lt;a href="https://developers.redhat.com/products/red-hat-openshift-data-science"&gt;OpenShift Data Science&lt;/a&gt; page to see our complete library of learning paths and other resources for developers and data scientists collaborating on intelligent applications.&lt;/p&gt; &lt;h2&gt;What is OpenShift Data Science?&lt;/h2&gt; &lt;p&gt;OpenShift Data Science is a platform that makes it easier for developers and data scientists to develop, deploy, and monitor &lt;a href="https://developers.redhat.com/topics/ai-ml"&gt;machine learning&lt;/a&gt; models. As a comprehensive environment built on top of &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt;, OpenShift Data Science integrates Jupyter notebooks—the core IDE where data scientists train models—with model development frameworks such as TensorFlow and PyTorch.&lt;/p&gt; &lt;p&gt;You can think of OpenShift Data Science as a meta-operator that sits above other &lt;a href="https://developers.redhat.com/topics/kubernetes/operators"&gt;Kubernetes Operators&lt;/a&gt; and combines them into a coherent, integrated environment. Currently, OpenShift Data Science partner technologies include:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Anaconda Commercial Edition for secure distribution and package management&lt;/li&gt; &lt;li&gt;IBM Watson Studio for building and managing models at scale and for AutoML&lt;/li&gt; &lt;li&gt;Intel OpenVINO and oneAPI AI analytics toolkits for optimizing and tuning models&lt;/li&gt; &lt;li&gt;Seldon Deploy for deploying, managing, and monitoring models&lt;/li&gt; &lt;li&gt;Starburst Galaxy for data integration&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Support for NVIDIA accelerated computing is coming very soon!&lt;/p&gt; &lt;h2&gt;Where can I learn more?&lt;/h2&gt; &lt;p&gt;Visit the &lt;a href="https://developers.redhat.com/products/red-hat-openshift-data-science"&gt;OpenShift Data Science&lt;/a&gt; landing page to learn more about how data scientists, data engineers, and application developers use this service to collaborate across the intelligent application life cycle.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/12/23/more-machine-learning-openshift-data-science" title="More machine learning with OpenShift Data Science"&gt;More machine learning with OpenShift Data Science&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Audrey Reznik</dc:creator><dc:date>2021-12-23T07:00:00Z</dc:date></entry><entry><title type="html">How to run WildFly on Openshift</title><link rel="alternate" href="http://www.mastertheboss.com/soa-cloud/openshift/using-wildfly-on-openshift/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=using-wildfly-on-openshift" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/soa-cloud/openshift/using-wildfly-on-openshift/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=using-wildfly-on-openshift</id><updated>2021-12-23T01:38:00Z</updated><content type="html">This tutorial will teach you how to run the latest version of WildFly on Openshift. We will then look at advanced options such as overriding the default server settings (WildFly 26 update). Finally, we will learn how to create a custom WildFly distribution using Galleon layers. Setting up WildFly Image Streams Openshift uses Image Streams ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">Important security vulnerability discovered</title><link rel="alternate" href="https://www.keycloak.org/2021/12/cve" /><author><name>Stian Thorgersen</name></author><id>https://www.keycloak.org/2021/12/cve</id><updated>2021-12-23T00:00:00Z</updated><content type="html">A flaw () was found in Keycloak version from 12.0.0 and before 15.1.1 which allows an attacker with any existing user account to create new default user accounts via the administrative REST API even when new user registration is disabled. In most situations the newly created user is the equivalent of a self-registered user, and does not have the ability to receive any additional roles or groups. However, there are some vectors that are harder to reproduce, but may result in additional privileges. We highly recommend everyone upgrade to Keycloak 15.1.1 or 16.1.0 as soon as possible. Keycloak 16.0.0 also includes the fix, but if you are not already running this version we recommend going straight to 16.1.0. If you are unable to upgrade we recommend mitigate the issue by blocking access to the user creation REST endpoint in the interim. This can be achieved with the following CLI commands: bin/jboss-cli.sh --connect /subsystem=undertow/configuration=filter/expression-filter=keycloakPathOverrideUsersCreateEndpoint:add( \ expression="(regex('^/auth/admin/realms/(.*)/users$') and method(POST))-&gt; response-code(400)" \ ) /subsystem=undertow/server=default-server/host=default-host/filter-ref=keycloakPathOverrideUsersCreateEndpoint:add() This will block both valid and invalid attempts at creating new users, including requests from the Keycloak admin console. Alternatively, the path /auth/admin/realms/.*/users and method POST, or /auth/admin completely, can be blocked with a firewall. For more information about the flaw please view and .</content><dc:creator>Stian Thorgersen</dc:creator></entry><entry><title>How to use Quarkus with the Service Binding Operator</title><link rel="alternate" href="https://developers.redhat.com/articles/2021/12/22/how-use-quarkus-service-binding-operator" /><author><name>Ioannis Kanellos</name></author><id>3392814a-3a5d-44ed-987f-7562c22d88d2</id><updated>2021-12-22T07:00:00Z</updated><published>2021-12-22T07:00:00Z</published><summary type="html">&lt;p&gt;In the seven years since &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; was released, there have been various efforts to simplify the process of consuming and binding to services from Kubernetes clusters. While discovering a service isn't much of an issue if you employ a well-known set of conventions, getting the credentials and other details required to access that service is sometimes trickier.&lt;/p&gt; &lt;p&gt;The &lt;a href="https://svc-cat.io"&gt;Kubernetes Service Catalog&lt;/a&gt; was an attempt to simplify provisioning and binding to services, but it seems to have lost momentum. The lack of uniformity between providers, differences in how each service communicates binding information, and the fact that developers tend to favor operators for provisioning services all made the Service Catalog hard to use in practice.&lt;/p&gt; &lt;p&gt;The &lt;a href="https://github.com/redhat-developer/service-binding-operator"&gt;Service Binding Operator&lt;/a&gt; for Kubernetes and &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt; is a more recent initiative. It stays out of the way of service provisioning, leaving that to operators. Instead, it focuses on how to best communicate binding information to the application. An interesting part of the specification is the &lt;a href="https://github.com/servicebinding/spec#workload-projection"&gt;workload projection&lt;/a&gt;, which defines a directory structure that will be mounted to the application container when binding occurs in order to pass all the required binding information: type, URI, and credentials&lt;/p&gt; &lt;p&gt;Other parts of the specification are related to the &lt;code&gt;ServiceBinding&lt;/code&gt; resource, which controls which services are bound to which application, and how.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/products/quarkus/overview"&gt;Quarkus&lt;/a&gt;, which already supports the workload-projection part of the Service Binding specification, recently received enhancements for service binding. In this article, you'll learn how to automatically generate a &lt;code&gt;ServiceBinding&lt;/code&gt; resource, then go through the whole process from installing operators to configuring and deploying an application.&lt;/p&gt; &lt;h2&gt;A note about the example&lt;/h2&gt; &lt;p&gt;In the example, you will use &lt;a href="https://kind.sigs.k8s.io/"&gt;kind&lt;/a&gt; to install the Service Binding Operator and the &lt;a href="https://github.com/CrunchyData/postgres-operator"&gt;Postgres Operator from Crunchy Data&lt;/a&gt;. After that, you will create a PostgreSQL cluster, and finally create a simple todo application, deploying it and binding it to the provisioned cluster. Before you begin, you may want to take a look at the &lt;a href="https://redhat-developer.github.io/service-binding-operator/userguide/getting-started/quick-start.html"&gt;Service Binding Operator Quick Start Guide&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Set up your clusters&lt;/h2&gt; &lt;p&gt;Begin by creating a new cluster with &lt;code&gt;kind&lt;/code&gt;. (If you've already created one, or don't use &lt;code&gt;kind&lt;/code&gt; at all, you can skip this step.)&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;kind create cluster&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You'll install both of the operators used in our example through the &lt;a href="https://operatorhub.io"&gt;OperatorHub&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Install the Operator Lifecycle Manager&lt;/h3&gt; &lt;p&gt;The first step is to install the &lt;a href="https://olm.operatorframework.io/"&gt;Operator Lifecycle Manager&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;curl -sL https://github.com/operator-framework/operator-lifecycle-manager/releases/download/v0.19.1/install.sh | bash -s v0.19.1 &lt;/code&gt; &lt;/pre&gt; &lt;h3&gt;Install the Service Binding Operator&lt;/h3&gt; &lt;p&gt;Next, you'll install the Service Binding Operator:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;kubectl create -f https://operatorhub.io/install/service-binding-operator.yaml&lt;/code&gt; &lt;/pre&gt; &lt;p&gt;Before moving to the next step, verify the installation with the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;kubectl get csv -n operators -w&lt;/code&gt; &lt;/pre&gt; &lt;p&gt;When the &lt;code&gt;phase&lt;/code&gt; of the Service Binding Operator is &lt;code&gt;Succeeded&lt;/code&gt;, you can proceed.&lt;/p&gt; &lt;h3&gt;Install the Postgres Operator&lt;/h3&gt; &lt;p&gt;Use the following command to install the Postgres Operator from Crunchy Data:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;kubectl create -f https://operatorhub.io/install/postgresql.yaml &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;As you did before, you'll want to verify the installation:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;kubectl get csv -n operators -w&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When the &lt;code&gt;phase&lt;/code&gt; of the operator is &lt;code&gt;Succeeded&lt;/code&gt;, you can move to the next stage.&lt;/p&gt; &lt;h2&gt;Create a PostgreSQL cluster&lt;/h2&gt; &lt;p&gt;To begin this process, create a new namespace where you'll install your cluster and application:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;kubectl create ns demo kubectl config set-context --current --namespace=demo&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To create the cluster, you need to apply the following custom resource:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; apiVersion: postgres-operator.crunchydata.com/v1beta1 kind: PostgresCluster metadata: name: pg-cluster namespace: demo spec: image: registry.developers.crunchydata.com/crunchydata/crunchy-postgres-ha:centos8-13.4-0 postgresVersion: 13 instances: - name: instance1 dataVolumeClaimSpec: accessModes: - "ReadWriteOnce" resources: requests: storage: 1Gi backups: pgbackrest: image: registry.developers.crunchydata.com/crunchydata/crunchy-pgbackrest:centos8-2.33-2 repos: - name: repo1 volume: volumeClaimSpec: accessModes: - "ReadWriteOnce" resources: requests: storage: 1Gi - name: repo2 volume: volumeClaimSpec: accessModes: - "ReadWriteOnce" resources: requests: storage: 1Gi proxy: pgBouncer: image: registry.developers.crunchydata.com/crunchydata/crunchy-pgbouncer:centos8-1.15-2 &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;This resource has been borrowed from the &lt;em&gt;Service Binding Operator Quick Start Guide&lt;/em&gt;. Save that file as &lt;code&gt;pg-cluster.yml&lt;/code&gt; and apply it using &lt;code&gt;kubectl&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;kubectl apply -f ~/pg-cluster.yml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now check the pods to verify the installation:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;kubectl get pods -n demo&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Create the Quarkus application&lt;/h2&gt; &lt;p&gt;Next, you'll create a simple Quarkus todo application that will connect to PostgreSQL via Hibernate and Panache. The todo application is a simple rest API for creating, reading, and deleting todo entries in a PostgreSQL database. It is heavily inspired by Clement Escoffier's &lt;a href="https://github.com/cescoffier/quarkus-todo-app"&gt;Quarkus todo app&lt;/a&gt; but focuses less on presentation and more on the binding aspect.&lt;/p&gt; &lt;p&gt;Generate the application using the following Maven command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;mvn io.quarkus.platform:quarkus-maven-plugin:2.5.0.Final:create -DprojectGroupId=org.acme -DprojectArtifactId=todo-example -DclassName="org.acme.TodoResource" -Dpath="/todo" &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;Next, add all of the required extensions for connecting to PostgreSQL, generate the required Kubernetes resources, and build a &lt;a href="https://developers.redhat.com/topics/containers"&gt;container&lt;/a&gt; image for the application using Docker:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;./mvnw quarkus:add-extension -Dextensions="resteasy-jackson,jdbc-postgresql,hibernate-orm-panache,kubernetes,kubernetes-service-binding,container-image-docker" &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;At this point, you need to create a simple entity:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;package org.acme; import javax.persistence.Column; import javax.persistence.Entity; import io.quarkus.hibernate.orm.panache.PanacheEntity; @Entity public class Todo extends PanacheEntity { @Column(length = 40, unique = true) public String title; public boolean completed; public Todo() { } public Todo(String title, Boolean completed) { this.title = title; } } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Then, expose it via REST:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;package org.acme; import javax.transaction.Transactional; import javax.ws.rs.*; import javax.ws.rs.core.Response; import javax.ws.rs.core.Response.Status; import java.util.List; @Path("/todo") public class TodoResource { @GET @Path("/") public List&lt;Todo&gt; getAll() { return Todo.listAll(); } @GET @Path("/{id}") public Todo get(@PathParam("id") Long id) { Todo entity = Todo.findById(id); if (entity == null) { throw new WebApplicationException("Todo with id of " + id + " does not exist.", Status.NOT_FOUND); } return entity; } @POST @Path("/") @Transactional public Response create(Todo item) { item.persist(); return Response.status(Status.CREATED).entity(item).build(); } @GET @Path("/{id}/complete") @Transactional public Response complete(@PathParam("id") Long id) { Todo entity = Todo.findById(id); entity.id = id; entity.completed = true; return Response.ok(entity).build(); } @DELETE @Transactional @Path("/{id}") public Response delete(@PathParam("id") Long id) { Todo entity = Todo.findById(id); if (entity == null) { throw new WebApplicationException("Todo with id of " + id + " does not exist.", Status.NOT_FOUND); } entity.delete(); return Response.noContent().build(); } } &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Bind to the target cluster&lt;/h2&gt; &lt;p&gt;In order to bind the PostgreSQL service to the application, you must either provide a &lt;code&gt;ServiceBinding&lt;/code&gt; resource or have it generated. To have the binding generated for you, you need to provide the following service coordinates:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;code&gt;apiVersion&lt;/code&gt;: &lt;code&gt;postgres-operator.crunchydata.com/v1beta1&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Kind: &lt;code&gt;PostgresCluster&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Name: &lt;code&gt;pg-cluster&lt;/code&gt;, prefixed with &lt;code&gt;quarkus.kubernetes-service-binding.services.&lt;id&gt;&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;You can see these coordinates in the following listing:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;quarkus.kubernetes-service-binding.services.my-db.api-version=postgres-operator.crunchydata.com/v1beta1 quarkus.kubernetes-service-binding.services.my-db.kind=PostgresCluster quarkus.kubernetes-service-binding.services.my-db.name=pg-cluster &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Note that the &lt;code&gt;id&lt;/code&gt; is just used to group properties together and can be any text.&lt;/p&gt; &lt;p&gt;You also need to configure the &lt;code&gt;datasource&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;quarkus.datasource.db-kind=postgresql quarkus.hibernate-orm.database.generation=drop-and-create quarkus.hibernate-orm.sql-load-script=import.sql &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This sample application will not push the image to a registry, but just loads it to the cluster, so use &lt;code&gt;IfNotPresent&lt;/code&gt; as the image pull policy:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;quarkus.kubernetes.image-pull-policy=IfNotPresent&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The application properties file should look like this:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;quarkus.kubernetes-service-binding.services.my-db.api-version=postgres-operator.crunchydata.com/v1beta1 quarkus.kubernetes-service-binding.services.my-db.kind=PostgresCluster quarkus.kubernetes-service-binding.services.my-db.name=pg-cluster quarkus.datasource.db-kind=postgresql quarkus.hibernate-orm.database.generation=drop-and-create quarkus.hibernate-orm.sql-load-script=import.sql quarkus.kubernetes.image-pull-policy=IfNotPresent &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Prepare for deployment&lt;/h2&gt; &lt;p&gt;Before you deploy, you need to perform a container image build, load the image to the cluster, and generate the resource.&lt;/p&gt; &lt;p&gt;First, build the container image:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;mvn clean install -Dquarkus.container-image.build=true -DskipTests &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Note that this instruction assumes that you have Docker up and running.&lt;/p&gt; &lt;p&gt;Next, you'll load the Docker image to the cluster:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;kind load docker-image iocanel/todo-example:1.0.0-SNAPSHOT &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;If you're using &lt;a href="https://minikube.sigs.k8s.io/docs/start/"&gt;minikube&lt;/a&gt; instead of Docker, execute the following to rebuild the image:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;eval $(minikube docker-env) &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;When using tools like &lt;code&gt;kind&lt;/code&gt; or &lt;code&gt;minikube&lt;/code&gt;, it is generally a good idea to change the image pull policy to &lt;code&gt;IfNotPresent&lt;/code&gt; as you did in this example. Doing this avoids unnecessary pulls, because most of the time the image will be loaded from the local Docker daemon.&lt;/p&gt; &lt;h2&gt;Deploy the application&lt;/h2&gt; &lt;p&gt;Next, generate the deployment manifest, including the &lt;code&gt;ServiceBinding&lt;/code&gt;, and apply them on Kubernetes:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;mvn clean install -Dquarkus.kubernetes.deploy=true -DskipTests&lt;/code&gt; &lt;/pre&gt; &lt;p&gt;Now, verify that everything is up and running:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;kubectl get pods -n demo -w&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Verify the installation&lt;/h2&gt; &lt;p&gt;The simplest way to verify that everything works as expected is to port forward to a local HTTP port and access the &lt;code&gt;/todo&lt;/code&gt; endpoint:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;kubectl port-forward service/todo-example 8080:80&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Point your browser to &lt;a href="http://localhost:8080/todo"&gt;http://localhost:8080/todo&lt;/a&gt; and enjoy!&lt;/p&gt; &lt;h2&gt;A look ahead&lt;/h2&gt; &lt;p&gt;I am very excited about recent progress on the service binding front. In the near future, we may be able to reduce the amount of configuration necessary with the use of smart conventions (such as assuming that the custom resource name is the same as the database name unless explicitly specified otherwise) and a reasonable set of defaults (such as assuming that for PostgreSQL the default operator is Crunchy Data's Postgres Operator). In such a scenario, you could bind to services with no configuration without sacrificing flexibility or customizability. I hope you are as excited as I am by this prospect!&lt;/p&gt; &lt;p&gt;See the following resources to learn more about service binding and the Service Binding Operator:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2021/10/27/announcing-service-binding-operator-10-ga"&gt;Announcing Service Binding Operator 1.0 GA&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2019/12/20/service-binding-operator-the-operator-in-action"&gt;Service Binding Operator: The Operator in action&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2021/11/03/how-use-service-binding-rabbitmq"&gt;How to use service binding with RabbitMQ&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/12/22/how-use-quarkus-service-binding-operator" title="How to use Quarkus with the Service Binding Operator"&gt;How to use Quarkus with the Service Binding Operator&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Ioannis Kanellos</dc:creator><dc:date>2021-12-22T07:00:00Z</dc:date></entry><entry><title>JBoss Tools 4.21.2.AM1 for Eclipse 2021-09</title><link rel="alternate" type="text/html" href="https://tools.jboss.org/blog/4.21.2.am1.html" /><category term="release" /><category term="jbosstools" /><category term="devstudio" /><category term="jbosscentral" /><author><name>jeffmaury</name></author><id>https://tools.jboss.org/blog/4.21.2.am1.html</id><updated>2021-12-24T08:18:06Z</updated><published>2021-12-22T00:00:00Z</published><content type="html">&lt;div&gt;&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Happy to announce 4.21.2.AM1 (Developer Milestone 1) build for Eclipse 2021-09.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Downloads available at &lt;a href="https://tools.jboss.org/downloads/jbosstools/2021-09/4.21.2.AM1.html"&gt;JBoss Tools 4.21.2.AM1&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="what-is-new"&gt;&lt;a class="anchor" href="#what-is-new"&gt;&lt;/a&gt;What is New?&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Full info is at &lt;a href="https://tools.jboss.org/documentation/whatsnew/jbosstools/4.21.2.AM1.html"&gt;this page&lt;/a&gt;. Some highlights are below.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="quarkus-tools"&gt;&lt;a class="anchor" href="#quarkus-tools"&gt;&lt;/a&gt;Quarkus Tools&lt;/h3&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="quarkus-stream-selection-in-the-new-quarkus-project-wizard"&gt;&lt;a class="anchor" href="#quarkus-stream-selection-in-the-new-quarkus-project-wizard"&gt;&lt;/a&gt;Quarkus stream selection in the new Quarkus project wizard&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;When a new Quarkus project/module is to be generated, it is now possible to select the Quarkus stream (see &lt;a href="https://quarkus.io/blog/quarkus-2x-platform-quarkiverse-registry/"&gt;this article&lt;/a&gt;) on which the generated application will be based on.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;By default, the recommended (latest release) will be selected but you can choose another one:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://tools.jboss.org/documentation/whatsnew/quarkus/images/quarkus31.gif" alt="quarkus31" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="enhanced-code-completion-in-java-files"&gt;&lt;a class="anchor" href="#enhanced-code-completion-in-java-files"&gt;&lt;/a&gt;Enhanced code completion in Java files&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;When you want to define a fallback method thanks to the &lt;code&gt;@Fallback&lt;/code&gt; annotation from MicroProfile Fault Tolerance, the code completion is activated on the &lt;code&gt;fallbackMethod&lt;/code&gt; member and will propose you available target methods.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://tools.jboss.org/documentation/whatsnew/quarkus/images/quarkus32.gif" alt="quarkus32" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="quarkus-launch-configuration-workspace-resolution"&gt;&lt;a class="anchor" href="#quarkus-launch-configuration-workspace-resolution"&gt;&lt;/a&gt;Quarkus launch configuration workspace resolution&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;When you define a Quarkus launch/debug configuration, it is linked to a specific project from your workspace. If this project has a dependency on another project from the workspace, it will be resolved against the workspace and you don’t have to install the dependency in the local Maven/Gradle cache so that it can be resolved.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="hibernate-tools"&gt;&lt;a class="anchor" href="#hibernate-tools"&gt;&lt;/a&gt;Hibernate Tools&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;A number of additions and updates have been performed on the available Hibernate runtime providers.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect3"&gt; &lt;h4 id="runtime-provider-updates"&gt;&lt;a class="anchor" href="#runtime-provider-updates"&gt;&lt;/a&gt;Runtime Provider Updates&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The Hibernate 5.6 runtime provider now incorporates Hibernate Core version 5.6.1.Final and Hibernate Tools version 5.6.1.Final.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The Hibernate 5.4 runtime provider now incorporates Hibernate Core version 5.4.8.Final and Hibernate Tools version 5.4.8.Final.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The Hibernate 5.3 runtime provider now incorporates Hibernate Core version 5.3.24.Final and Hibernate Tools version 5.3.24.Final.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Enjoy!&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Jeff Maury&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;</content><summary>Happy to announce 4.21.2.AM1 (Developer Milestone 1) build for Eclipse 2021-09. Downloads available at JBoss Tools 4.21.2.AM1. What is New? Full info is at this page. Some highlights are below. Quarkus Tools Quarkus stream selection in the new Quarkus project wizard When a new Quarkus project/module is to be generated, it is now possible to select the Quarkus stream (see this article) on which the generated application will be based on. By default, the recommended (latest release) will be selected but you can choose another one: Enhanced code completion in Java files When you want to define a fallback method thanks to the @Fallback annotation from MicroProfile Fault Tolerance,...</summary><dc:creator>jeffmaury</dc:creator><dc:date>2021-12-22T00:00:00Z</dc:date></entry><entry><title type="html">How to handle Exceptions in JAX-RS applications</title><link rel="alternate" href="http://www.mastertheboss.com/jboss-frameworks/resteasy/how-to-handle-exceptions-in-jax-rs-applications/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=how-to-handle-exceptions-in-jax-rs-applications" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/jboss-frameworks/resteasy/how-to-handle-exceptions-in-jax-rs-applications/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=how-to-handle-exceptions-in-jax-rs-applications</id><updated>2021-12-21T10:02:32Z</updated><content type="html">This article will teach you how to handle Exceptions properly in RESTful Web services using JAX-RS API and some advanced options which are available with RESTEasy and Quarkus runtime. Overview of REST Exceptions As for every Java classes, REST Endpoints can throw in their code both checked Exceptions (i.e. classes extending java.lang.Exception) and unchecked (i.e. ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>Prevent Python dependency confusion attacks with Thoth</title><link rel="alternate" href="https://developers.redhat.com/articles/2021/12/21/prevent-python-dependency-confusion-attacks-thoth" /><author><name>Fridolin Pokorny</name></author><id>ae654f04-c49e-4f00-acd0-060b226f40bf</id><updated>2021-12-21T07:00:00Z</updated><published>2021-12-21T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/topics/python"&gt;Python&lt;/a&gt; became popular as a casual scripting language but has since evolved into the corporate space, where it is used for &lt;a href="https://developers.redhat.com/topics/data-science"&gt;data science&lt;/a&gt; and &lt;a href="https://developers.redhat.com/topics/ai-ml"&gt;machine learning&lt;/a&gt; applications, among others. Because Python is a high-level programming language, developers often use it to quickly prototype applications. &lt;a href="https://docs.python.org/3/extending/extending.html"&gt;Python native extensions&lt;/a&gt; make it easy to optimize any computation-intensive parts of the application using a lower-level programming language like &lt;a href="https://developers.redhat.com/topics/c"&gt;C or C++&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;For applications that need to scale, we can use &lt;a href="https://github.com/sclorg/s2i-python-container"&gt;Python Source-to-Image tooling&lt;/a&gt; (S2I) to convert a Python application into a &lt;a href="https://developers.redhat.com/topics/containers"&gt;container&lt;/a&gt; image. That image can then be orchestrated and scaled using cluster orchestrators such as &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; or &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt;. All of these features together provide a convenient platform for solving problems using Python-based solutions that scale, are maintainable, and are easily extensible.&lt;/p&gt; &lt;p&gt;As a community-based project, the main source of open-source Python packages is the &lt;a href="https://pypi.org/"&gt;Python Package Index&lt;/a&gt; (PyPI). As of this writing, PyPI hosts more than 3 million releases, and the number of releases available continues to grow exponentially. PyPI's growth is an indicator of Python's popularity worldwide.&lt;/p&gt; &lt;p&gt;However, Python's community-driven dependency resolvers were not designed for corporate environments, and that has led to dependency management issues and vulnerabilities in the Python ecosystem. This article describes some of the risks involved in resolving Python dependencies and introduces &lt;a href="https://thoth-station.ninja/"&gt;Project Thoth&lt;/a&gt;'s tools for avoiding them.&lt;/p&gt; &lt;h2&gt;Dependency management in Python&lt;/h2&gt; &lt;p&gt;The Python package installer, &lt;a href="https://pypi.org/project/pip"&gt;pip&lt;/a&gt;, is a popular tool for resolving Python application dependencies. Unfortunately, pip does not provide a way to manage lock files for application dependencies. Pip resolves dependencies to the latest possible versions at the given point in time, so the resolution is highly dependent on the time when the resolution process was triggered. Dependency problems such as &lt;em&gt;overpinning&lt;/em&gt; (requesting too wide a range of versions) frequently introduce issues to the Python application stack.&lt;/p&gt; &lt;p&gt;To address lock file management issues, the Python community developed tools such as &lt;a href="https://pypi.org/project/pip-tools/"&gt;pip-tools&lt;/a&gt;, &lt;a href="https://pipenv.pypa.io/"&gt;Pipenv&lt;/a&gt;, and &lt;a href="https://python-poetry.org/"&gt;Poetry&lt;/a&gt;. (Our &lt;a href="https://developers.redhat.com/articles/2021/05/19/micropipenv-installing-python-dependencies-containerized-applications"&gt;article introducing micropipenv&lt;/a&gt; includes an overview of these projects.)&lt;/p&gt; &lt;p&gt;The &lt;a href="https://pypi.org/"&gt;Python Package Index&lt;/a&gt; is the primary index consulted by pip. In some cases, applications need libraries from other Python package indexes. For these, pip provides the &lt;a href="https://pip.pypa.io/en/stable/cli/pip_install/#install-index-url"&gt;--index-url&lt;/a&gt; and &lt;a href="https://pip.pypa.io/en/stable/cli/pip_install/#install-extra-index-url"&gt;--extra-index-url&lt;/a&gt; options. Most of the time, there are two primary reasons you might need to install dependencies from Python package sources other than PyPI:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Installing specific builds of packages whose features cannot be expressed using wheel tags, or that do not meet &lt;a href="https://github.com/pypa/manylinux"&gt;manylinux standards&lt;/a&gt;; e.g., the &lt;a href="https://tensorflow.pypi.thoth-station.ninja/"&gt;AVX2-enabled builds of TensorFlow&lt;/a&gt; hosted on the Python package index of the Artificial Intelligence Center of Excellence (AICoE).&lt;/li&gt; &lt;li&gt;Installing packages that should not be hosted on PyPI, such as packages specific to one company or patched versions of libraries used only for testing.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Why Python is vulnerable to dependency confusion attacks&lt;/h2&gt; &lt;p&gt;The pip options &lt;code&gt;--index-url&lt;/code&gt; and &lt;code&gt;--extra-index-url&lt;/code&gt; provide a way to specify alternate Python package indexes for resolving and installing Python packages. The first option, &lt;code&gt;--index-url&lt;/code&gt;, specifies the main Python package index for resolving Python packages, and defaults to PyPI. When you need a second package index, you can include the &lt;code&gt;--extra-index-url&lt;/code&gt; option as many times as needed. The resolution logic in pip first uses the main index, then, if the required package or version is not found there, it checks the secondary indexes.&lt;/p&gt; &lt;p&gt;Thus, although you can specify the order in which indexes are consulted, the configuration is not specified for each package individually. Moreover, the index configuration is applied for transitive dependencies introduced by direct dependencies, as well.&lt;/p&gt; &lt;p&gt;To bypass this order, application developers can manage requirements with hashes that are checked during installation and resolution to differentiate releases. This solution is unintuitive and error-prone, however. Although we encourage keeping hashes in lock files for integrity checks, they should be managed automatically using the appropriate tools.&lt;/p&gt; &lt;p&gt;Now, let’s imagine a dependency named &lt;code&gt;foo&lt;/code&gt; that a company uses on a private package index. Suppose a different package with the same name is hosted on PyPI. An unexpected glitch—such as a temporary network issue when resolving the company private package index—could lead the application to import the &lt;code&gt;foo&lt;/code&gt; package from PyPI in default setups. In the worst case, the package published on PyPI might be a &lt;a href="https://medium.com/@alex.birsan/dependency-confusion-4a5d60fec610"&gt;malicious alternative&lt;/a&gt; that reveals company secrets to an attacker.&lt;/p&gt; &lt;p&gt;This issue also applies to pip-tools, Pipenv, and Poetry). Pipenv provides a way to configure a Python package index for a specific package, but it does not enforce the specified configuration. All the mentioned dependency resolution tools treat multiple Python package indexes supplied as mirrors.&lt;/p&gt; &lt;h2&gt;Using Thoth to resolve dependency confusion&lt;/h2&gt; &lt;p&gt;&lt;a href="https://thoth-station.ninja/"&gt;Thoth&lt;/a&gt; is a project sponsored by Red Hat that takes a fresh look at the complex needs of Python applications and &lt;a href="https://developers.redhat.com/articles/2021/11/17/customize-python-dependency-resolution-machine-learning"&gt;moves the resolution process to the cloud&lt;/a&gt;. Naturally, being cloud-based has its advantages and disadvantages depending on how the tool is used.&lt;/p&gt; &lt;p&gt;Because Thoth moves dependency resolution to the cloud, a central authority can resolve application requirements. This central authority can be configured with fine-grained control over which application dependencies go into desired environments. For instance, you could handle dependencies in test environments and production environments differently.&lt;/p&gt; &lt;p&gt;Thoth's resolver pre-aggregates information about Python packages from various Python package indexes. This way, the resolver can monitor Python packages published on PyPI, on the AICoE-specific TensorFlow index, on a &lt;a href="https://www.operate-first.cloud/community-handbook/pulp/usage.md"&gt;corporate Pulp Python index&lt;/a&gt;, on the &lt;a href="https://download.pytorch.org/whl/cu111/"&gt;PyTorch CUDA 11.1 index&lt;/a&gt;, and on &lt;a href="https://download.pytorch.org/whl/cpu/"&gt;builds for CPU use&lt;/a&gt;, which the PyTorch community provides for specific cases. Moreover, the cloud-based resolver &lt;a href="https://thoth-station.ninja/docs/developers/adviser/security.html"&gt;introspects the published packages with respect to security&lt;/a&gt; or &lt;a href="https://github.com/thoth-station/cve-update-job"&gt;vulnerabilities&lt;/a&gt; (see &lt;a href="https://github.com/pypa/advisory-db"&gt;PyPA’s Python Packaging Advisory Database&lt;/a&gt;) to additionally guide a &lt;a href="https://developers.redhat.com/articles/2021/09/29/secure-your-python-applications-thoth-recommendations"&gt;secure resolution process&lt;/a&gt;.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; Please &lt;a href="https://github.com/thoth-station/support/issues/new/choose"&gt;contact the Thoth team&lt;/a&gt; if you wish to register your own Python package index to Thoth.&lt;/p&gt; &lt;h3&gt;Solver rules in Thoth&lt;/h3&gt; &lt;p&gt;A central authority can be configured to allow or block packages or specific package releases that are hosted on the Python package indexes. This feature is called &lt;em&gt;solver rules&lt;/em&gt; and is maintained by a Thoth operator.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; See &lt;a href="https://thoth-station.ninja/docs/developers/adviser/deployment.html#configuring-solver-rules"&gt;Configuring solver rules&lt;/a&gt; in the Thoth documentation for more about this topic. Also check out our &lt;a href="https://www.youtube.com/watch?v=wjMNOyGupbs"&gt;YouTube video demonstrating solver rules&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;You can use solver rules to allow the Thoth operator to specify which Python packages or specific releases can be considered during the resolution process, respecting the Python package indexes registered when a request is made to the cloud-based resolver. You can also use solver rules to block the analysis of packages that are considered too old, are no longer supported, or simply don't adhere to company policies.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;a href="https://github.com/thoth-station/support/issues/new/choose"&gt;Report issues with open source Python packages&lt;/a&gt; to help us create new solver rules.&lt;/p&gt; &lt;h3&gt;Strict index configuration&lt;/h3&gt; &lt;p&gt;Another feature in Thoth is the ability to &lt;a href="https://thoth-station.ninja/docs/developers/adviser/experimental_features.html#strict-index-configuration"&gt;configure a strict Python package index configuration&lt;/a&gt;. By default, the recommendation engine considers all the packages published on the indexes it monitors and uses a &lt;a href="https://developers.redhat.com/articles/2021/11/17/customize-python-dependency-resolution-machine-learning"&gt;reinforcement learning algorithm&lt;/a&gt; to come up with a set of packages that are considered most appropriate. However, in some situations, Thoth users want to suppress this behavior and explicitly configure Python package indexes for consuming Python packages on their own.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you are interested in the strict index configuration, please &lt;a href="https://thoth-station.ninja/docs/developers/adviser/experimental_features.html#strict-index-configuration"&gt;browse the documentation&lt;/a&gt; and &lt;a href="https://www.youtube.com/watch?v=p6fjVQ0aUPE"&gt;watch our video demonstration&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Prescriptions&lt;/h3&gt; &lt;p&gt;Thoth also supports a &lt;a href="https://developers.redhat.com/articles/2021/09/22/thoth-prescriptions-resolving-python-dependencies"&gt;mechanism called prescriptions&lt;/a&gt; that provides additional, detailed guidelines for package resolution. Prescriptions are analogous to manifests in Kubernetes and OpenShift. A manifest lists the desired state of the cluster, and the machinery behind the cluster orchestrator tries to create and maintain the desired state. Similarly, prescriptions provide a declarative way to specify the resolution process for the particular dependencies and Python package indexes used.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; See the &lt;a href="https://thoth-station.ninja/docs/developers/adviser/prescription.html"&gt;prescriptions section&lt;/a&gt; in the Thoth documentation for more about this feature. You can also browse Thoth's &lt;a href="https://github.com/thoth-station/prescriptions/"&gt;prescriptions repository&lt;/a&gt; for prescriptions available for open source Python projects. See our &lt;a href="https://developers.redhat.com/articles/2021/09/22/thoth-prescriptions-resolving-python-dependencies"&gt;article about prescriptions&lt;/a&gt; for more insight into this concept.&lt;/p&gt; &lt;p&gt;Thoth's &lt;a href="https://developers.redhat.com/articles/2021/11/17/customize-python-dependency-resolution-machine-learning"&gt;reinforcement learning algorithm&lt;/a&gt; searches for a solution that satisfies application requirements, taking prescriptions into account. This algorithm provides the power to adjust the resolution process in whatever manner users desire. Adjustments to the resolution process can be made using &lt;a href="https://thoth-station.ninja/docs/developers/adviser/prescription/should_include.html#should-include-labels"&gt;labeled requests to the resolver&lt;/a&gt; which can pick prescriptions that match specified criteria written in YAML files. An example can be consuming all the packages solely from one package index (such as a Python package index hosted using &lt;a href="https://pulpproject.org/"&gt;Pulp&lt;/a&gt;) that hosts packages that can be considered as trusted for Thoth users.&lt;/p&gt; &lt;h2&gt;About Project Thoth&lt;/h2&gt; &lt;p&gt;As part of Project Thoth, we are accumulating knowledge to help Python developers create healthy applications. If you would like to follow project updates, please &lt;a href="https://www.youtube.com/channel/UClUIDuq_hQ6vlzmqM59B2Lw"&gt;subscribe to our YouTube channel&lt;/a&gt; or follow us on the &lt;a href="https://twitter.com/thothstation"&gt;@ThothStation Twitter handle&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/12/21/prevent-python-dependency-confusion-attacks-thoth" title="Prevent Python dependency confusion attacks with Thoth"&gt;Prevent Python dependency confusion attacks with Thoth&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Fridolin Pokorny</dc:creator><dc:date>2021-12-21T07:00:00Z</dc:date></entry></feed>
